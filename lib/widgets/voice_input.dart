// =======================================================
// voice_input.dart
// âœ… åŠŸèƒ½èªªæ˜ï¼š
//   1ï¸âƒ£ é•·æŒ‰éŒ„éŸ³ï¼Œæ¾æ‰‹çµæŸ
//   2ï¸âƒ£ å³æ™‚æ”¶é›† PCM raw audio chunk
//   3ï¸âƒ£ çµæŸå¾Œå°‡ buffer ä¸­éŸ³è¨Šè½‰æˆ Uint8List
//   4ï¸âƒ£ é€é gRPC ChatStream ä¸²æµé€åˆ°å¾Œç«¯
// =======================================================

import 'dart:async';
import 'dart:typed_data';
import 'package:flutter/material.dart';
import 'package:flutter_sound/flutter_sound.dart'; // éŒ„éŸ³å·¥å…·
import 'package:permission_handler/permission_handler.dart'; // æ¬Šé™è™•ç†
import 'package:grpc/grpc.dart' as grpc;

// gRPC Stubï¼ˆprotoc ç”Ÿæˆï¼‰
import '../generated/blind_assist.pbgrpc.dart';

class VoiceInput extends StatefulWidget {
  const VoiceInput({Key? key}) : super(key: key);

  @override
  State<VoiceInput> createState() => _VoiceInputState();
}

class _VoiceInputState extends State<VoiceInput> {
  // === éŒ„éŸ³ç›¸é—œ ===
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  bool _isRecording = false; // æ¨™è¨˜ç›®å‰æ˜¯å¦åœ¨éŒ„éŸ³
  final List<int> _rawDataBuffer = []; // PCM bufferï¼ˆå¦‚æœé‚„è¦ä¿ç•™ï¼‰

  StreamController<Uint8List>? _audioStreamController;
  StreamSubscription<Uint8List>? _recorderSubscription;

  // === gRPC ç›¸é—œ ===
  late final grpc.ClientChannel _channel;
  late final GeminiLiveClient _grpcClient;
  late final StreamController<ClientRequest> _reqController;

  @override
  void initState() {
    super.initState();
    _initGrpc(); // åˆå§‹åŒ– gRPC channel & client & ä¸²æµ
    _initRecorder(); // åˆå§‹åŒ–éŒ„éŸ³å™¨ä¸¦è«‹æ±‚æ¬Šé™
  }

  @override
  void dispose() async {
    await _recorderSubscription?.cancel();
    await _recorder.closeRecorder();
    await _reqController.close();
    await _channel.shutdown(); // <- await
    super.dispose();
  }

  /// åˆå§‹åŒ– gRPC Channelã€Clientï¼Œä¸¦å•Ÿå‹• ChatStream é›™å‘ä¸²æµ
  void _initGrpc() {
    _channel = grpc.ClientChannel(
      'blind-grpc-server-617941879669.asia-east1.run.app',
      port: 443,
      options: grpc.ChannelOptions(
        credentials: grpc.ChannelCredentials.secure(), // æ”¾åœ¨ options è£¡é¢
        idleTimeout: const Duration(seconds: 60), // é¿å…å¤ªä¹…æ²’æœ‰æ´»å‹•å°±è¢« server é—œç·š
        codecRegistry: grpc.CodecRegistry(codecs: const [
          grpc.GzipCodec(), // å¯é¸ï¼šgzip å£“ç¸®
          grpc.IdentityCodec(),
        ]),
      ),
    );

    _grpcClient = GeminiLiveClient(_channel);
    _reqController = StreamController<ClientRequest>();

    // 1ï¸âƒ£ å…ˆé€ InitialConfigRequest
    _reqController.sink.add(ClientRequest(
      initialConfig: InitialConfigRequest(
        modelName: 'gemini-1', // â† å¯æ”¹
        responseModalities: ['TEXT', 'AUDIO'],
      ),
    ));

    // 2ï¸âƒ£ å•Ÿå‹•é›™å‘ä¸²æµï¼Œä¸¦ç›£è½ä¼ºæœå™¨å›æ‡‰
    _grpcClient.chatStream(_reqController.stream).listen(
          _onServerResponse,
          onError: (e) => debugPrint('âŒ gRPC éŒ¯èª¤ï¼š$e'),
        );
  }

  /// åˆå§‹åŒ–éŒ„éŸ³å™¨ï¼šè«‹æ±‚éº¥å…‹é¢¨æ¬Šé™å¾Œé–‹å•ŸéŒ„éŸ³å™¨
  Future<void> _initRecorder() async {
    final status = await Permission.microphone.request();
    if (status.isGranted) {
      await _recorder.openRecorder();
      // è¨­å®šéŒ„éŸ³è¨‚é–±é »ç‡ï¼ˆå½±éŸ¿ chunk å¤§å°ï¼‰
      await _recorder
          .setSubscriptionDuration(const Duration(milliseconds: 100));
    } else {
      debugPrint('â— éº¥å…‹é¢¨æ¬Šé™è¢«æ‹’çµ•ï¼Œç„¡æ³•éŒ„éŸ³');
    }
  }

  /// é–‹å§‹éŒ„éŸ³ï¼š
  /// - æ¸…ç©º bufferï¼ˆå¦‚è¦ä¿ç•™ï¼‰
  /// - å»ºç«‹ PCM chunk StreamController
  /// - startRecorder ä¸¦æŠŠ sink æ¥åˆ° controller
  Future<void> _startRecording() async {
    _rawDataBuffer.clear();
    _audioStreamController = StreamController<Uint8List>();
    _recorderSubscription = _audioStreamController!.stream.listen((chunk) {
      // 1ï¸âƒ£ ä¿ç•™åœ¨æœ¬åœ° bufferï¼ˆå¯é¸ï¼‰
      _rawDataBuffer.addAll(chunk);
      // 2ï¸âƒ£ é€é gRPC æ‰“åŒ…æˆ AudioPart ä¸²æµé€å‡º
      _reqController.sink.add(ClientRequest(
        clientAudioPart: AudioPart(
          audioData: chunk,
          mimeType: 'audio/pcm',
          sampleRate: 16000,
        ),
      ));
    });

    await _recorder.startRecorder(
      toStream: _audioStreamController!.sink,
      codec: Codec.pcm16, // PCM 16-bit raw
      sampleRate: 16000, // æ¯ç§’ 16000 samples
      numChannels: 1, // å–®è²é“
    );

    setState(() => _isRecording = true);
  }

  /// åœæ­¢éŒ„éŸ³ï¼š
  /// - stopRecorder
  /// - å–æ¶ˆè¨‚é–± & é—œé–‰ controller
  /// - é€ end_of_turn=true çµ¦ä¼ºæœå™¨
  Future<void> _stopRecording() async {
    await _recorder.stopRecorder();
    await _recorderSubscription?.cancel();
    await _audioStreamController?.close();
    setState(() => _isRecording = false);

    // é€šçŸ¥ä¼ºæœå™¨é€™ä¸€è¼ªèªéŸ³å·²ç¶“çµæŸ
    _reqController.sink.add(ClientRequest(endOfTurn: true));
  }

  /// è™•ç†ä¼ºæœå™¨å›æ‡‰
  void _onServerResponse(ServerResponse resp) {
    if (resp.hasTextPart()) {
      final text = resp.textPart.text;
      debugPrint('ğŸ’¬ å›å‚³æ–‡å­—ï¼š$text');
      // TODO: é¡¯ç¤ºåˆ°ç•«é¢ä¸Š
    }
    if (resp.hasGeminiAudioPart()) {
      final audio = resp.geminiAudioPart.audioData;
      debugPrint('ğŸ”ˆ æ”¶åˆ°èªéŸ³å›è¦†ï¼Œå…± ${audio.length} bytes');
      // TODO: æ’­æ”¾æˆ–å­˜æª”
    }
    if (resp.hasErrorPart()) {
      debugPrint('âš ï¸ éŒ¯èª¤ ${resp.errorPart.code}: ${resp.errorPart.message}');
    }
    if (resp.turnComplete) {
      debugPrint('ğŸ”” Gemini å›åˆçµæŸ');
    }
  }

  @override
  Widget build(BuildContext context) {
    return Listener(
      onPointerDown: (_) => _startRecording(), // é•·æŒ‰é–‹å§‹
      onPointerUp: (_) => _stopRecording(), // æ”¾é–‹åœæ­¢
      child: FloatingActionButton(
        backgroundColor: _isRecording
            ? const Color.fromARGB(255, 219, 54, 54) // éŒ„éŸ³ä¸­ç´…è‰²
            : const Color.fromARGB(255, 113, 52, 52), // å¾…å‘½
        onPressed: () {}, // ä½¿ç”¨ Listener è€Œé onPressed
        child: Icon(
          _isRecording ? Icons.mic : Icons.mic_none,
          size: 60,
        ),
      ),
    );
  }
}
